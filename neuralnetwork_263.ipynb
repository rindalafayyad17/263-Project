{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralnetwork_263.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZIMc6RlOliE",
        "outputId": "733b513b-1afa-4de2-a75b-8a43ea447109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.4.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 30 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 40 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 61 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 71 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 81 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from scipy import stats\n",
        "from scipy.stats import zscore\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "import pydot\n",
        "import seaborn as sns\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import os, shutil\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load in data \n",
        "url = 'https://raw.githubusercontent.com/rindalafayyad17/263-Project/main/diabetes_012_health_indicators_BRFSS2015.csv'\n",
        "diabetes = pd.read_csv(url)\n"
      ],
      "metadata": {
        "id": "3guvcIgbOmkk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpybOz6jPJNq",
        "outputId": "3b032624-ea18-4814-c23e-695a3ffa774a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253680, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes['Diabetes_012'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orwHtmWmhTAr",
        "outputId": "4649a4b5-3da1-4812-c2e2-d9744de9536b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    213703\n",
              "2.0     35346\n",
              "1.0      4631\n",
              "Name: Diabetes_012, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "iYmraV_zPOCh",
        "outputId": "c86faf40-229a-445d-8e28-87b50d2e3d36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
              "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
              "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
              "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
              "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
              "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
              "\n",
              "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
              "0                   0.0           0.0     0.0  ...            1.0   \n",
              "1                   0.0           1.0     0.0  ...            0.0   \n",
              "2                   0.0           0.0     1.0  ...            1.0   \n",
              "3                   0.0           1.0     1.0  ...            1.0   \n",
              "4                   0.0           1.0     1.0  ...            1.0   \n",
              "\n",
              "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
              "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
              "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
              "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
              "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
              "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
              "\n",
              "   Income  \n",
              "0     3.0  \n",
              "1     1.0  \n",
              "2     8.0  \n",
              "3     6.0  \n",
              "4     4.0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86aa3ee0-d410-4a6f-aaec-9172142d17a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diabetes_012</th>\n",
              "      <th>HighBP</th>\n",
              "      <th>HighChol</th>\n",
              "      <th>CholCheck</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoker</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>HeartDiseaseorAttack</th>\n",
              "      <th>PhysActivity</th>\n",
              "      <th>Fruits</th>\n",
              "      <th>...</th>\n",
              "      <th>AnyHealthcare</th>\n",
              "      <th>NoDocbcCost</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86aa3ee0-d410-4a6f-aaec-9172142d17a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86aa3ee0-d410-4a6f-aaec-9172142d17a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86aa3ee0-d410-4a6f-aaec-9172142d17a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need several preprocessing steps: \n",
        "\n",
        "0. Remove missing rows. We have tons of data so lets just try to drop any rows with NA values. **Turns out there are no missing values**\n",
        "\n",
        "1. Identify the continuous and catgeorical variables. \n",
        "\n",
        "2. Continuous vairables need to be normalized, that is subtract mean and divide by standard deviation. Look at SCM class notes for assistance as sklearn should have package to do this. '\n",
        "\n",
        "3. Categorical variables will need to be encoded appropriately. \n",
        "\n",
        "Continuous variables: \n",
        "- BMI, MentHlth, PhysHlth\n",
        "\n",
        "\n",
        "Categorical Variables:\n",
        "\n",
        "*Binary:* \n",
        "- HighBp, HighCl, CholCheck, Smoker, Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, Veggies, HvyAlcoholConsumption, AnyHealthcare, NoDocbcCost, GenHlth, DiffWalk, Sex\n",
        "\n",
        "*Ordinal*\n",
        "\n",
        "- Age, Education, Income"
      ],
      "metadata": {
        "id": "iVjfU7SxQvI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using category encoders instead\n",
        "ce_OHE = ce.OneHotEncoder(cols=['Age','Education', 'Income'])\n",
        "\n",
        "diabetes_final = ce_OHE.fit_transform(diabetes)\n",
        "print(diabetes_final.head())\n",
        "diabetes_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuz0lPMMn37w",
        "outputId": "01c603a2-87cb-46ce-d9b1-249a441e1f6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "\n",
            "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  Education_5  Education_6  \\\n",
            "0                   0.0           0.0     0.0  ...            0            0   \n",
            "1                   0.0           1.0     0.0  ...            0            0   \n",
            "2                   0.0           0.0     1.0  ...            0            0   \n",
            "3                   0.0           1.0     1.0  ...            0            0   \n",
            "4                   0.0           1.0     1.0  ...            0            0   \n",
            "\n",
            "   Income_1  Income_2  Income_3  Income_4  Income_5  Income_6  Income_7  \\\n",
            "0         1         0         0         0         0         0         0   \n",
            "1         0         1         0         0         0         0         0   \n",
            "2         0         0         1         0         0         0         0   \n",
            "3         0         0         0         1         0         0         0   \n",
            "4         0         0         0         0         1         0         0   \n",
            "\n",
            "   Income_8  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "\n",
            "[5 rows x 46 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(253680, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to make training, validation and test split\n",
        "features = diabetes_final.drop('Diabetes_012', axis = 1)\n",
        "\n",
        "# reshape labels and encode them\n",
        "ce_OHE = ce.OneHotEncoder(cols=['Diabetes_012'])\n",
        "labels = ce_OHE.fit_transform(diabetes_final)\n",
        "labels = labels.iloc[:,0:3]"
      ],
      "metadata": {
        "id": "S823aaITo-Gh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into training and testing set \n",
        "# set aside 20% of train and test data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
        "    test_size=0.2, shuffle = True, random_state = 356)\n",
        "\n",
        "# Use the same function above for the validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
        "    test_size=0.25, random_state= 356) # 0.25 x 0.8 = 0.2"
      ],
      "metadata": {
        "id": "SBhNxRz03Hjj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pHU6OFSY187d",
        "outputId": "416be2d1-1ab2-4375-dfd0-83bc5c0e3e3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Diabetes_012_1  Diabetes_012_2  Diabetes_012_3\n",
              "0               1               0               0\n",
              "1               1               0               0\n",
              "2               1               0               0\n",
              "3               1               0               0\n",
              "4               1               0               0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b830725f-3fa1-4f27-a0eb-7293d9dcabd6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diabetes_012_1</th>\n",
              "      <th>Diabetes_012_2</th>\n",
              "      <th>Diabetes_012_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b830725f-3fa1-4f27-a0eb-7293d9dcabd6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b830725f-3fa1-4f27-a0eb-7293d9dcabd6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b830725f-3fa1-4f27-a0eb-7293d9dcabd6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "63fiByzQ2TbQ",
        "outputId": "b6fc8781-6c51-4e85-d76b-19e73f7b7a87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
              "0     1.0       1.0        1.0  40.0     1.0     0.0                   0.0   \n",
              "1     0.0       0.0        0.0  25.0     1.0     0.0                   0.0   \n",
              "2     1.0       1.0        1.0  28.0     0.0     0.0                   0.0   \n",
              "3     1.0       0.0        1.0  27.0     0.0     0.0                   0.0   \n",
              "4     1.0       1.0        1.0  24.0     0.0     0.0                   0.0   \n",
              "\n",
              "   PhysActivity  Fruits  Veggies  ...  Education_5  Education_6  Income_1  \\\n",
              "0           0.0     0.0      1.0  ...            0            0         1   \n",
              "1           1.0     0.0      0.0  ...            0            0         0   \n",
              "2           0.0     1.0      0.0  ...            0            0         0   \n",
              "3           1.0     1.0      1.0  ...            0            0         0   \n",
              "4           1.0     1.0      1.0  ...            0            0         0   \n",
              "\n",
              "   Income_2  Income_3  Income_4  Income_5  Income_6  Income_7  Income_8  \n",
              "0         0         0         0         0         0         0         0  \n",
              "1         1         0         0         0         0         0         0  \n",
              "2         0         1         0         0         0         0         0  \n",
              "3         0         0         1         0         0         0         0  \n",
              "4         0         0         0         1         0         0         0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a97b43d-47db-436d-ac80-cb4f2a927ee3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HighBP</th>\n",
              "      <th>HighChol</th>\n",
              "      <th>CholCheck</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoker</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>HeartDiseaseorAttack</th>\n",
              "      <th>PhysActivity</th>\n",
              "      <th>Fruits</th>\n",
              "      <th>Veggies</th>\n",
              "      <th>...</th>\n",
              "      <th>Education_5</th>\n",
              "      <th>Education_6</th>\n",
              "      <th>Income_1</th>\n",
              "      <th>Income_2</th>\n",
              "      <th>Income_3</th>\n",
              "      <th>Income_4</th>\n",
              "      <th>Income_5</th>\n",
              "      <th>Income_6</th>\n",
              "      <th>Income_7</th>\n",
              "      <th>Income_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a97b43d-47db-436d-ac80-cb4f2a927ee3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a97b43d-47db-436d-ac80-cb4f2a927ee3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a97b43d-47db-436d-ac80-cb4f2a927ee3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build and compile model \n",
        "# Define model\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(256, activation='sigmoid', input_dim = 45),\n",
        "  layers.Dropout(0.5),\n",
        "\n",
        "  layers.Dense(128, activation='sigmoid'), \n",
        "  layers.Dropout(0.5),\n",
        "\n",
        "  layers.Dense(32, activation='sigmoid'), \n",
        "\n",
        "  layers.Dense(3, activation='softmax') # 3 categories\n",
        "])\n",
        "\n",
        "# model compile function\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.RMSprop(),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "mTUhGJyLop-H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, \n",
        "          y_train, \n",
        "          epochs = 200, #change epochs to 100 after testing\n",
        "          batch_size = 50,\n",
        "          validation_data=(X_val, y_val)\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCSIy6FVp7Jk",
        "outputId": "65ecfcc1-9a83-405e-8460-0e274d4a14c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3045/3045 [==============================] - 9s 3ms/step - loss: 0.4251 - accuracy: 0.8427 - val_loss: 0.3995 - val_accuracy: 0.8500\n",
            "Epoch 2/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4061 - accuracy: 0.8453 - val_loss: 0.3996 - val_accuracy: 0.8488\n",
            "Epoch 3/200\n",
            "3045/3045 [==============================] - 7s 2ms/step - loss: 0.4045 - accuracy: 0.8464 - val_loss: 0.4026 - val_accuracy: 0.8456\n",
            "Epoch 4/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4045 - accuracy: 0.8460 - val_loss: 0.4054 - val_accuracy: 0.8461\n",
            "Epoch 5/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4040 - accuracy: 0.8463 - val_loss: 0.4021 - val_accuracy: 0.8500\n",
            "Epoch 6/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4050 - accuracy: 0.8458 - val_loss: 0.4034 - val_accuracy: 0.8488\n",
            "Epoch 7/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4057 - accuracy: 0.8458 - val_loss: 0.4012 - val_accuracy: 0.8501\n",
            "Epoch 8/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4056 - accuracy: 0.8458 - val_loss: 0.4053 - val_accuracy: 0.8467\n",
            "Epoch 9/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4058 - accuracy: 0.8454 - val_loss: 0.4078 - val_accuracy: 0.8421\n",
            "Epoch 10/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4070 - accuracy: 0.8454 - val_loss: 0.4046 - val_accuracy: 0.8444\n",
            "Epoch 11/200\n",
            "3045/3045 [==============================] - 9s 3ms/step - loss: 0.4079 - accuracy: 0.8461 - val_loss: 0.4036 - val_accuracy: 0.8489\n",
            "Epoch 12/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4068 - accuracy: 0.8459 - val_loss: 0.4033 - val_accuracy: 0.8499\n",
            "Epoch 13/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4077 - accuracy: 0.8453 - val_loss: 0.4115 - val_accuracy: 0.8420\n",
            "Epoch 14/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4087 - accuracy: 0.8451 - val_loss: 0.4039 - val_accuracy: 0.8465\n",
            "Epoch 15/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4079 - accuracy: 0.8455 - val_loss: 0.4026 - val_accuracy: 0.8499\n",
            "Epoch 16/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4076 - accuracy: 0.8451 - val_loss: 0.4037 - val_accuracy: 0.8479\n",
            "Epoch 17/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4080 - accuracy: 0.8457 - val_loss: 0.4073 - val_accuracy: 0.8478\n",
            "Epoch 18/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4075 - accuracy: 0.8466 - val_loss: 0.4062 - val_accuracy: 0.8456\n",
            "Epoch 19/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4084 - accuracy: 0.8461 - val_loss: 0.4050 - val_accuracy: 0.8499\n",
            "Epoch 20/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4081 - accuracy: 0.8454 - val_loss: 0.4054 - val_accuracy: 0.8496\n",
            "Epoch 21/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4083 - accuracy: 0.8453 - val_loss: 0.4056 - val_accuracy: 0.8497\n",
            "Epoch 22/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4093 - accuracy: 0.8462 - val_loss: 0.4062 - val_accuracy: 0.8455\n",
            "Epoch 23/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4092 - accuracy: 0.8453 - val_loss: 0.4050 - val_accuracy: 0.8501\n",
            "Epoch 24/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4090 - accuracy: 0.8463 - val_loss: 0.4046 - val_accuracy: 0.8491\n",
            "Epoch 25/200\n",
            "3045/3045 [==============================] - 9s 3ms/step - loss: 0.4109 - accuracy: 0.8456 - val_loss: 0.4101 - val_accuracy: 0.8492\n",
            "Epoch 26/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4125 - accuracy: 0.8458 - val_loss: 0.4089 - val_accuracy: 0.8499\n",
            "Epoch 27/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4141 - accuracy: 0.8465 - val_loss: 0.4096 - val_accuracy: 0.8501\n",
            "Epoch 28/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4151 - accuracy: 0.8466 - val_loss: 0.4153 - val_accuracy: 0.8493\n",
            "Epoch 29/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4148 - accuracy: 0.8460 - val_loss: 0.4118 - val_accuracy: 0.8493\n",
            "Epoch 30/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4148 - accuracy: 0.8460 - val_loss: 0.4168 - val_accuracy: 0.8434\n",
            "Epoch 31/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4132 - accuracy: 0.8460 - val_loss: 0.4118 - val_accuracy: 0.8484\n",
            "Epoch 32/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4141 - accuracy: 0.8460 - val_loss: 0.4127 - val_accuracy: 0.8501\n",
            "Epoch 33/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4153 - accuracy: 0.8465 - val_loss: 0.4143 - val_accuracy: 0.8496\n",
            "Epoch 34/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4174 - accuracy: 0.8468 - val_loss: 0.4125 - val_accuracy: 0.8499\n",
            "Epoch 35/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4193 - accuracy: 0.8461 - val_loss: 0.4175 - val_accuracy: 0.8440\n",
            "Epoch 36/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4182 - accuracy: 0.8472 - val_loss: 0.4148 - val_accuracy: 0.8504\n",
            "Epoch 37/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4176 - accuracy: 0.8467 - val_loss: 0.4106 - val_accuracy: 0.8497\n",
            "Epoch 38/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4154 - accuracy: 0.8455 - val_loss: 0.4113 - val_accuracy: 0.8490\n",
            "Epoch 39/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4159 - accuracy: 0.8456 - val_loss: 0.4162 - val_accuracy: 0.8432\n",
            "Epoch 40/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4174 - accuracy: 0.8455 - val_loss: 0.4138 - val_accuracy: 0.8476\n",
            "Epoch 41/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4201 - accuracy: 0.8472 - val_loss: 0.4198 - val_accuracy: 0.8496\n",
            "Epoch 42/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4220 - accuracy: 0.8457 - val_loss: 0.4175 - val_accuracy: 0.8494\n",
            "Epoch 43/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4235 - accuracy: 0.8465 - val_loss: 0.4245 - val_accuracy: 0.8448\n",
            "Epoch 44/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4231 - accuracy: 0.8466 - val_loss: 0.4233 - val_accuracy: 0.8467\n",
            "Epoch 45/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4242 - accuracy: 0.8466 - val_loss: 0.4237 - val_accuracy: 0.8451\n",
            "Epoch 46/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4247 - accuracy: 0.8469 - val_loss: 0.4223 - val_accuracy: 0.8501\n",
            "Epoch 47/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4245 - accuracy: 0.8468 - val_loss: 0.4194 - val_accuracy: 0.8497\n",
            "Epoch 48/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4217 - accuracy: 0.8467 - val_loss: 0.4234 - val_accuracy: 0.8428\n",
            "Epoch 49/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4177 - accuracy: 0.8460 - val_loss: 0.4138 - val_accuracy: 0.8480\n",
            "Epoch 50/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4156 - accuracy: 0.8460 - val_loss: 0.4147 - val_accuracy: 0.8473\n",
            "Epoch 51/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4168 - accuracy: 0.8456 - val_loss: 0.4141 - val_accuracy: 0.8499\n",
            "Epoch 52/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4191 - accuracy: 0.8456 - val_loss: 0.4149 - val_accuracy: 0.8488\n",
            "Epoch 53/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4192 - accuracy: 0.8459 - val_loss: 0.4162 - val_accuracy: 0.8478\n",
            "Epoch 54/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4226 - accuracy: 0.8462 - val_loss: 0.4262 - val_accuracy: 0.8484\n",
            "Epoch 55/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4232 - accuracy: 0.8467 - val_loss: 0.4124 - val_accuracy: 0.8499\n",
            "Epoch 56/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4215 - accuracy: 0.8466 - val_loss: 0.4120 - val_accuracy: 0.8508\n",
            "Epoch 57/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4204 - accuracy: 0.8463 - val_loss: 0.4112 - val_accuracy: 0.8496\n",
            "Epoch 58/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4178 - accuracy: 0.8453 - val_loss: 0.4092 - val_accuracy: 0.8494\n",
            "Epoch 59/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4146 - accuracy: 0.8465 - val_loss: 0.4104 - val_accuracy: 0.8468\n",
            "Epoch 60/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4142 - accuracy: 0.8451 - val_loss: 0.4099 - val_accuracy: 0.8481\n",
            "Epoch 61/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4140 - accuracy: 0.8455 - val_loss: 0.4100 - val_accuracy: 0.8496\n",
            "Epoch 62/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4151 - accuracy: 0.8459 - val_loss: 0.4146 - val_accuracy: 0.8479\n",
            "Epoch 63/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4151 - accuracy: 0.8460 - val_loss: 0.4122 - val_accuracy: 0.8500\n",
            "Epoch 64/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4161 - accuracy: 0.8456 - val_loss: 0.4141 - val_accuracy: 0.8464\n",
            "Epoch 65/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4173 - accuracy: 0.8459 - val_loss: 0.4135 - val_accuracy: 0.8445\n",
            "Epoch 66/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4152 - accuracy: 0.8461 - val_loss: 0.4074 - val_accuracy: 0.8476\n",
            "Epoch 67/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4152 - accuracy: 0.8452 - val_loss: 0.4138 - val_accuracy: 0.8457\n",
            "Epoch 68/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4173 - accuracy: 0.8453 - val_loss: 0.4136 - val_accuracy: 0.8458\n",
            "Epoch 69/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4194 - accuracy: 0.8448 - val_loss: 0.4113 - val_accuracy: 0.8495\n",
            "Epoch 70/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4170 - accuracy: 0.8453 - val_loss: 0.4106 - val_accuracy: 0.8500\n",
            "Epoch 71/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4197 - accuracy: 0.8456 - val_loss: 0.4129 - val_accuracy: 0.8482\n",
            "Epoch 72/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4207 - accuracy: 0.8447 - val_loss: 0.4157 - val_accuracy: 0.8491\n",
            "Epoch 73/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4240 - accuracy: 0.8450 - val_loss: 0.4230 - val_accuracy: 0.8496\n",
            "Epoch 74/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4221 - accuracy: 0.8461 - val_loss: 0.4199 - val_accuracy: 0.8486\n",
            "Epoch 75/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4204 - accuracy: 0.8457 - val_loss: 0.4148 - val_accuracy: 0.8484\n",
            "Epoch 76/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4238 - accuracy: 0.8459 - val_loss: 0.4195 - val_accuracy: 0.8490\n",
            "Epoch 77/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4259 - accuracy: 0.8461 - val_loss: 0.4260 - val_accuracy: 0.8478\n",
            "Epoch 78/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4256 - accuracy: 0.8461 - val_loss: 0.4216 - val_accuracy: 0.8481\n",
            "Epoch 79/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4253 - accuracy: 0.8458 - val_loss: 0.4201 - val_accuracy: 0.8479\n",
            "Epoch 80/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4268 - accuracy: 0.8462 - val_loss: 0.4257 - val_accuracy: 0.8479\n",
            "Epoch 81/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4318 - accuracy: 0.8466 - val_loss: 0.4293 - val_accuracy: 0.8472\n",
            "Epoch 82/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4355 - accuracy: 0.8464 - val_loss: 0.4348 - val_accuracy: 0.8472\n",
            "Epoch 83/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4383 - accuracy: 0.8462 - val_loss: 0.4351 - val_accuracy: 0.8497\n",
            "Epoch 84/200\n",
            "3045/3045 [==============================] - 8s 2ms/step - loss: 0.4364 - accuracy: 0.8468 - val_loss: 0.4323 - val_accuracy: 0.8488\n",
            "Epoch 85/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4351 - accuracy: 0.8465 - val_loss: 0.4350 - val_accuracy: 0.8486\n",
            "Epoch 86/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4362 - accuracy: 0.8461 - val_loss: 0.4330 - val_accuracy: 0.8479\n",
            "Epoch 87/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4379 - accuracy: 0.8467 - val_loss: 0.4316 - val_accuracy: 0.8487\n",
            "Epoch 88/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4352 - accuracy: 0.8467 - val_loss: 0.4333 - val_accuracy: 0.8470\n",
            "Epoch 89/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4348 - accuracy: 0.8477 - val_loss: 0.4304 - val_accuracy: 0.8493\n",
            "Epoch 90/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4352 - accuracy: 0.8462 - val_loss: 0.4255 - val_accuracy: 0.8490\n",
            "Epoch 91/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4318 - accuracy: 0.8473 - val_loss: 0.4270 - val_accuracy: 0.8499\n",
            "Epoch 92/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4306 - accuracy: 0.8470 - val_loss: 0.4242 - val_accuracy: 0.8491\n",
            "Epoch 93/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4265 - accuracy: 0.8467 - val_loss: 0.4195 - val_accuracy: 0.8492\n",
            "Epoch 94/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4215 - accuracy: 0.8461 - val_loss: 0.4183 - val_accuracy: 0.8484\n",
            "Epoch 95/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4230 - accuracy: 0.8462 - val_loss: 0.4232 - val_accuracy: 0.8492\n",
            "Epoch 96/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4244 - accuracy: 0.8466 - val_loss: 0.4190 - val_accuracy: 0.8491\n",
            "Epoch 97/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4240 - accuracy: 0.8464 - val_loss: 0.4166 - val_accuracy: 0.8487\n",
            "Epoch 98/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4252 - accuracy: 0.8465 - val_loss: 0.4222 - val_accuracy: 0.8487\n",
            "Epoch 99/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4261 - accuracy: 0.8472 - val_loss: 0.4214 - val_accuracy: 0.8481\n",
            "Epoch 100/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4268 - accuracy: 0.8473 - val_loss: 0.4228 - val_accuracy: 0.8484\n",
            "Epoch 101/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4293 - accuracy: 0.8479 - val_loss: 0.4301 - val_accuracy: 0.8420\n",
            "Epoch 102/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4287 - accuracy: 0.8474 - val_loss: 0.4274 - val_accuracy: 0.8495\n",
            "Epoch 103/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4303 - accuracy: 0.8486 - val_loss: 0.4233 - val_accuracy: 0.8493\n",
            "Epoch 104/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4280 - accuracy: 0.8482 - val_loss: 0.4234 - val_accuracy: 0.8488\n",
            "Epoch 105/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4322 - accuracy: 0.8480 - val_loss: 0.4307 - val_accuracy: 0.8499\n",
            "Epoch 106/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4298 - accuracy: 0.8480 - val_loss: 0.4245 - val_accuracy: 0.8491\n",
            "Epoch 107/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4303 - accuracy: 0.8483 - val_loss: 0.4256 - val_accuracy: 0.8498\n",
            "Epoch 108/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4324 - accuracy: 0.8479 - val_loss: 0.4286 - val_accuracy: 0.8489\n",
            "Epoch 109/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4318 - accuracy: 0.8473 - val_loss: 0.4278 - val_accuracy: 0.8503\n",
            "Epoch 110/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4317 - accuracy: 0.8479 - val_loss: 0.4328 - val_accuracy: 0.8498\n",
            "Epoch 111/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4341 - accuracy: 0.8476 - val_loss: 0.4307 - val_accuracy: 0.8503\n",
            "Epoch 112/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4340 - accuracy: 0.8478 - val_loss: 0.4274 - val_accuracy: 0.8499\n",
            "Epoch 113/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4345 - accuracy: 0.8475 - val_loss: 0.4327 - val_accuracy: 0.8499\n",
            "Epoch 114/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4346 - accuracy: 0.8482 - val_loss: 0.4326 - val_accuracy: 0.8495\n",
            "Epoch 115/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4346 - accuracy: 0.8482 - val_loss: 0.4315 - val_accuracy: 0.8488\n",
            "Epoch 116/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4367 - accuracy: 0.8480 - val_loss: 0.4370 - val_accuracy: 0.8495\n",
            "Epoch 117/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4378 - accuracy: 0.8482 - val_loss: 0.4357 - val_accuracy: 0.8505\n",
            "Epoch 118/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4374 - accuracy: 0.8482 - val_loss: 0.4379 - val_accuracy: 0.8502\n",
            "Epoch 119/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4374 - accuracy: 0.8477 - val_loss: 0.4392 - val_accuracy: 0.8503\n",
            "Epoch 120/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4377 - accuracy: 0.8486 - val_loss: 0.4358 - val_accuracy: 0.8503\n",
            "Epoch 121/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4377 - accuracy: 0.8482 - val_loss: 0.4353 - val_accuracy: 0.8500\n",
            "Epoch 122/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4401 - accuracy: 0.8486 - val_loss: 0.4366 - val_accuracy: 0.8502\n",
            "Epoch 123/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4406 - accuracy: 0.8483 - val_loss: 0.4363 - val_accuracy: 0.8501\n",
            "Epoch 124/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4406 - accuracy: 0.8485 - val_loss: 0.4423 - val_accuracy: 0.8499\n",
            "Epoch 125/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4396 - accuracy: 0.8487 - val_loss: 0.4375 - val_accuracy: 0.8502\n",
            "Epoch 126/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4391 - accuracy: 0.8488 - val_loss: 0.4365 - val_accuracy: 0.8498\n",
            "Epoch 127/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4411 - accuracy: 0.8486 - val_loss: 0.4407 - val_accuracy: 0.8497\n",
            "Epoch 128/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4422 - accuracy: 0.8487 - val_loss: 0.4403 - val_accuracy: 0.8499\n",
            "Epoch 129/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4409 - accuracy: 0.8483 - val_loss: 0.4391 - val_accuracy: 0.8503\n",
            "Epoch 130/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4404 - accuracy: 0.8483 - val_loss: 0.4444 - val_accuracy: 0.8503\n",
            "Epoch 131/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4430 - accuracy: 0.8482 - val_loss: 0.4457 - val_accuracy: 0.8485\n",
            "Epoch 132/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4414 - accuracy: 0.8482 - val_loss: 0.4395 - val_accuracy: 0.8500\n",
            "Epoch 133/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4385 - accuracy: 0.8482 - val_loss: 0.4489 - val_accuracy: 0.8420\n",
            "Epoch 134/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4401 - accuracy: 0.8485 - val_loss: 0.4413 - val_accuracy: 0.8500\n",
            "Epoch 135/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4405 - accuracy: 0.8484 - val_loss: 0.4398 - val_accuracy: 0.8504\n",
            "Epoch 136/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4385 - accuracy: 0.8482 - val_loss: 0.4387 - val_accuracy: 0.8500\n",
            "Epoch 137/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4410 - accuracy: 0.8490 - val_loss: 0.4385 - val_accuracy: 0.8494\n",
            "Epoch 138/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4419 - accuracy: 0.8489 - val_loss: 0.4401 - val_accuracy: 0.8504\n",
            "Epoch 139/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4428 - accuracy: 0.8490 - val_loss: 0.4393 - val_accuracy: 0.8498\n",
            "Epoch 140/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4396 - accuracy: 0.8487 - val_loss: 0.4335 - val_accuracy: 0.8496\n",
            "Epoch 141/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4370 - accuracy: 0.8472 - val_loss: 0.4417 - val_accuracy: 0.8465\n",
            "Epoch 142/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4429 - accuracy: 0.8472 - val_loss: 0.4456 - val_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4449 - accuracy: 0.8477 - val_loss: 0.4424 - val_accuracy: 0.8498\n",
            "Epoch 144/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4454 - accuracy: 0.8489 - val_loss: 0.4419 - val_accuracy: 0.8499\n",
            "Epoch 145/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4426 - accuracy: 0.8484 - val_loss: 0.4400 - val_accuracy: 0.8493\n",
            "Epoch 146/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4412 - accuracy: 0.8479 - val_loss: 0.4374 - val_accuracy: 0.8487\n",
            "Epoch 147/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4383 - accuracy: 0.8469 - val_loss: 0.4387 - val_accuracy: 0.8420\n",
            "Epoch 148/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4336 - accuracy: 0.8469 - val_loss: 0.4412 - val_accuracy: 0.8492\n",
            "Epoch 149/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4359 - accuracy: 0.8474 - val_loss: 0.4345 - val_accuracy: 0.8498\n",
            "Epoch 150/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4365 - accuracy: 0.8477 - val_loss: 0.4357 - val_accuracy: 0.8498\n",
            "Epoch 151/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4361 - accuracy: 0.8474 - val_loss: 0.4352 - val_accuracy: 0.8493\n",
            "Epoch 152/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4364 - accuracy: 0.8484 - val_loss: 0.4325 - val_accuracy: 0.8498\n",
            "Epoch 153/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4340 - accuracy: 0.8469 - val_loss: 0.4357 - val_accuracy: 0.8500\n",
            "Epoch 154/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4356 - accuracy: 0.8476 - val_loss: 0.4354 - val_accuracy: 0.8504\n",
            "Epoch 155/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4349 - accuracy: 0.8478 - val_loss: 0.4397 - val_accuracy: 0.8504\n",
            "Epoch 156/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4384 - accuracy: 0.8480 - val_loss: 0.4369 - val_accuracy: 0.8498\n",
            "Epoch 157/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4369 - accuracy: 0.8476 - val_loss: 0.4408 - val_accuracy: 0.8484\n",
            "Epoch 158/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4372 - accuracy: 0.8481 - val_loss: 0.4399 - val_accuracy: 0.8486\n",
            "Epoch 159/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4396 - accuracy: 0.8477 - val_loss: 0.4375 - val_accuracy: 0.8492\n",
            "Epoch 160/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4414 - accuracy: 0.8478 - val_loss: 0.4473 - val_accuracy: 0.8503\n",
            "Epoch 161/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4420 - accuracy: 0.8469 - val_loss: 0.4462 - val_accuracy: 0.8420\n",
            "Epoch 162/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4433 - accuracy: 0.8484 - val_loss: 0.4402 - val_accuracy: 0.8504\n",
            "Epoch 163/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4442 - accuracy: 0.8476 - val_loss: 0.4469 - val_accuracy: 0.8489\n",
            "Epoch 164/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4464 - accuracy: 0.8484 - val_loss: 0.4458 - val_accuracy: 0.8482\n",
            "Epoch 165/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4433 - accuracy: 0.8479 - val_loss: 0.4502 - val_accuracy: 0.8486\n",
            "Epoch 166/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4463 - accuracy: 0.8493 - val_loss: 0.4480 - val_accuracy: 0.8503\n",
            "Epoch 167/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4463 - accuracy: 0.8486 - val_loss: 0.4520 - val_accuracy: 0.8497\n",
            "Epoch 168/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4468 - accuracy: 0.8483 - val_loss: 0.4500 - val_accuracy: 0.8503\n",
            "Epoch 169/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4457 - accuracy: 0.8488 - val_loss: 0.4464 - val_accuracy: 0.8498\n",
            "Epoch 170/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4410 - accuracy: 0.8478 - val_loss: 0.4448 - val_accuracy: 0.8503\n",
            "Epoch 171/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4437 - accuracy: 0.8487 - val_loss: 0.4428 - val_accuracy: 0.8492\n",
            "Epoch 172/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4443 - accuracy: 0.8486 - val_loss: 0.4448 - val_accuracy: 0.8493\n",
            "Epoch 173/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4422 - accuracy: 0.8481 - val_loss: 0.4409 - val_accuracy: 0.8501\n",
            "Epoch 174/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4439 - accuracy: 0.8484 - val_loss: 0.4455 - val_accuracy: 0.8494\n",
            "Epoch 175/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4470 - accuracy: 0.8489 - val_loss: 0.4484 - val_accuracy: 0.8499\n",
            "Epoch 176/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4434 - accuracy: 0.8485 - val_loss: 0.4431 - val_accuracy: 0.8498\n",
            "Epoch 177/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4423 - accuracy: 0.8476 - val_loss: 0.4458 - val_accuracy: 0.8494\n",
            "Epoch 178/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4437 - accuracy: 0.8476 - val_loss: 0.4464 - val_accuracy: 0.8497\n",
            "Epoch 179/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4448 - accuracy: 0.8484 - val_loss: 0.4504 - val_accuracy: 0.8500\n",
            "Epoch 180/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4467 - accuracy: 0.8488 - val_loss: 0.4471 - val_accuracy: 0.8496\n",
            "Epoch 181/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4478 - accuracy: 0.8493 - val_loss: 0.4499 - val_accuracy: 0.8477\n",
            "Epoch 182/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4455 - accuracy: 0.8480 - val_loss: 0.4433 - val_accuracy: 0.8497\n",
            "Epoch 183/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4448 - accuracy: 0.8487 - val_loss: 0.4488 - val_accuracy: 0.8501\n",
            "Epoch 184/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4433 - accuracy: 0.8488 - val_loss: 0.4440 - val_accuracy: 0.8495\n",
            "Epoch 185/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4431 - accuracy: 0.8486 - val_loss: 0.4480 - val_accuracy: 0.8498\n",
            "Epoch 186/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4464 - accuracy: 0.8483 - val_loss: 0.4526 - val_accuracy: 0.8453\n",
            "Epoch 187/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4464 - accuracy: 0.8485 - val_loss: 0.4491 - val_accuracy: 0.8497\n",
            "Epoch 188/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4455 - accuracy: 0.8493 - val_loss: 0.4485 - val_accuracy: 0.8500\n",
            "Epoch 189/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4441 - accuracy: 0.8491 - val_loss: 0.4466 - val_accuracy: 0.8496\n",
            "Epoch 190/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4443 - accuracy: 0.8494 - val_loss: 0.4445 - val_accuracy: 0.8499\n",
            "Epoch 191/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4437 - accuracy: 0.8491 - val_loss: 0.4454 - val_accuracy: 0.8498\n",
            "Epoch 192/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4444 - accuracy: 0.8496 - val_loss: 0.4434 - val_accuracy: 0.8499\n",
            "Epoch 193/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4457 - accuracy: 0.8487 - val_loss: 0.4473 - val_accuracy: 0.8501\n",
            "Epoch 194/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4464 - accuracy: 0.8489 - val_loss: 0.4494 - val_accuracy: 0.8498\n",
            "Epoch 195/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4417 - accuracy: 0.8477 - val_loss: 0.4399 - val_accuracy: 0.8499\n",
            "Epoch 196/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4382 - accuracy: 0.8478 - val_loss: 0.4419 - val_accuracy: 0.8489\n",
            "Epoch 197/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4381 - accuracy: 0.8489 - val_loss: 0.4403 - val_accuracy: 0.8502\n",
            "Epoch 198/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4441 - accuracy: 0.8486 - val_loss: 0.4449 - val_accuracy: 0.8495\n",
            "Epoch 199/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4440 - accuracy: 0.8488 - val_loss: 0.4441 - val_accuracy: 0.8499\n",
            "Epoch 200/200\n",
            "3045/3045 [==============================] - 8s 3ms/step - loss: 0.4421 - accuracy: 0.8490 - val_loss: 0.4456 - val_accuracy: 0.8506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save('Drive/diabetes.h5')"
      ],
      "metadata": {
        "id": "iGY_PposvjCO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model \n",
        "new_model = tf.keras.models.load_model(\"Drive/diabetes.h5\")\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyinEFZogH_k",
        "outputId": "e0748a3c-8309-4662-bfa8-6936ee37bf07"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               11776     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,899\n",
            "Trainable params: 48,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot of validation loss and train loss\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "train_acc  = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_acc  = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss, label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, label = 'Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "oqjHrLgVn22U",
        "outputId": "fe52d6f5-bfee-4d5a-aace-3cf089ef65ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff8e1e9ab90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test set accuracy \n",
        "test_loss, test_acc = new_model.evaluate(X_test, y_test)\n",
        "print(\"The test set accuracy is: \", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lblxrHCR4LMH",
        "outputId": "f4b2dc4c-65fb-461c-e639-7f6fb3607916"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1586/1586 [==============================] - 2s 1ms/step - loss: 0.4473 - accuracy: 0.8486\n",
            "The test set accuracy is:  0.8486281633377075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next steps: \n",
        "\n",
        "**Modeling**\n",
        "- normalize the continuous variables and rerun new model\n",
        "- try different parameters (probably not epochs and batch size) such as units in hidden layers, depth of layers, activation functions\n",
        "\n",
        "**Performance Evaluation**\n",
        "- Create 3 by 3 accuracy table (done with reservations -- see below) \n",
        "- Subset data by income level and recreate accuracy tables\n",
        "\n",
        "Unitless measures such as NPV,PPV may be better for classifcation depending on prevalence of diabetes/prediabetes in the dataset. "
      ],
      "metadata": {
        "id": "bFQlGuXo3bP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = new_model.predict(X_test) # need to make this into a vector again of [0,1,2] values and also make y_test back into vector of [0,1,2] "
      ],
      "metadata": {
        "id": "wDp7Hx3SFdsV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_proba.argmax(axis = 1) # want 0,1,2 vector\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c10fLrw-Hey-",
        "outputId": "f3756a8b-305f-4ee8-c67b-a0bef143df8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAqT4JAsH-P0",
        "outputId": "03b002cd-0764-4f7e-f395-ca7bb5db0c12"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       ...,\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to y_test to be single vector of 0,1,2 again\n",
        "y_test_lab = diabetes.iloc[y_test.index, :][\"Diabetes_012\"]"
      ],
      "metadata": {
        "id": "UU_WsErkKlrj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create accuracy table \n",
        "#importing confusion matrix\n",
        "confusion = confusion_matrix(y_test_lab, y_pred)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_lab, y_pred)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_lab, y_pred, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_lab, y_pred, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_lab, y_pred, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_lab, y_pred, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_lab, y_pred, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_lab, y_pred, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_lab, y_pred, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_lab, y_pred, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_lab, y_pred, average='weighted')))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_test_lab, y_pred, target_names=['No diabetes', 'Prediabetes', 'Diabetes']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPgbPXfAFE6O",
        "outputId": "bdd564b1-b653-4c76-a7c1-2d3cbbe9f4c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[41718   989     0]\n",
            " [  853    79     0]\n",
            " [ 5759  1338     0]]\n",
            "\n",
            "Accuracy: 0.82\n",
            "\n",
            "Micro Precision: 0.82\n",
            "Micro Recall: 0.82\n",
            "Micro F1-score: 0.82\n",
            "\n",
            "Macro Precision: 0.30\n",
            "Macro Recall: 0.35\n",
            "Macro F1-score: 0.32\n",
            "\n",
            "Weighted Precision: 0.73\n",
            "Weighted Recall: 0.82\n",
            "Weighted F1-score: 0.77\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " No diabetes       0.86      0.98      0.92     42707\n",
            " Prediabetes       0.03      0.08      0.05       932\n",
            "    Diabetes       0.00      0.00      0.00      7097\n",
            "\n",
            "    accuracy                           0.82     50736\n",
            "   macro avg       0.30      0.35      0.32     50736\n",
            "weighted avg       0.73      0.82      0.77     50736\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subset the Data (Income) and Recalculate Accuracy"
      ],
      "metadata": {
        "id": "R_8ztO6jib8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 8 is above $75,000, 5 is below 35,000\n",
        " # maybe start with split of below 5 and above 5 \n",
        "diabetes['Income'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaPAbHf1iloI",
        "outputId": "2d884ad7-13b8-4837-922b-b2f8f1d39bd0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0    90385\n",
              "7.0    43219\n",
              "6.0    36470\n",
              "5.0    25883\n",
              "4.0    20135\n",
              "3.0    15994\n",
              "2.0    11783\n",
              "1.0     9811\n",
              "Name: Income, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X test of only > 5 income \n",
        "X_test_high = X_test[(X_test[\"Income_6\"] == 1.0) | (X_test[\"Income_7\"] == 1.0) | (X_test[\"Income_8\"] == 1.0)]\n",
        "high_indx = X_test_high.index\n",
        "\n",
        "# X test of only <= 5 income \n",
        "X_test_low = X_test[(X_test[\"Income_1\"] == 1.0) | (X_test[\"Income_2\"] == 1.0) | (X_test[\"Income_3\"] == 1.0) | (X_test[\"Income_4\"] == 1.0) | (X_test[\"Income_5\"] == 1.0)]\n",
        "low_indx = X_test_low.index\n",
        "\n",
        "\n",
        "# y test of only same sebsets above\n",
        "y_test_high = y_test[y_test.index.isin(high_indx)]\n",
        "y_test_low = y_test[y_test.index.isin(low_indx)]\n",
        "\n",
        "y_test_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1o2Zff45lU3c",
        "outputId": "73c4a75c-2e57-4765-ed83-740b4e9c3eef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Diabetes_012_1  Diabetes_012_2  Diabetes_012_3\n",
              "204300               1               0               0\n",
              "187954               1               0               0\n",
              "205236               1               0               0\n",
              "104585               1               0               0\n",
              "113139               1               0               0\n",
              "...                ...             ...             ...\n",
              "252276               1               0               0\n",
              "94259                1               0               0\n",
              "241228               1               0               0\n",
              "62941                1               0               0\n",
              "152849               1               0               0\n",
              "\n",
              "[16133 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7007896-b7bc-4d05-8378-4d506cf54a4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diabetes_012_1</th>\n",
              "      <th>Diabetes_012_2</th>\n",
              "      <th>Diabetes_012_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>204300</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187954</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205236</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104585</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113139</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252276</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94259</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241228</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62941</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152849</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16133 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7007896-b7bc-4d05-8378-4d506cf54a4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7007896-b7bc-4d05-8378-4d506cf54a4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7007896-b7bc-4d05-8378-4d506cf54a4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# high index accuracies \n",
        "y_proba_high = new_model.predict(X_test_high)"
      ],
      "metadata": {
        "id": "dpMDBTB3s_pi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hl4ZfCTtVip",
        "outputId": "120afc92-51e7-4679-d81a-ed8fbef33066"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6217235 , 0.33456403, 0.0437125 ],\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       ...,\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329],\n",
              "       [0.8908643 , 0.09192236, 0.01721329]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_high = y_proba_high.argmax(axis = 1) # want 0,1,2 vector\n",
        "y_pred_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGT_fSHAtg2V",
        "outputId": "59a25557-1301-482b-d1c5-d024e34fa69c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to y_test to be single vector of 0,1,2 again\n",
        "y_test_lab_high = diabetes.iloc[y_test_high.index, :]['Diabetes_012']\n",
        "y_test_lab_high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5fd-H2JtsFb",
        "outputId": "f66fe174-ee50-4900-ca60-a44e996dd2b3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204300    0.0\n",
              "187954    0.0\n",
              "205236    0.0\n",
              "104585    0.0\n",
              "113139    0.0\n",
              "         ... \n",
              "252276    0.0\n",
              "94259     0.0\n",
              "241228    0.0\n",
              "62941     0.0\n",
              "152849    0.0\n",
              "Name: Diabetes_012, Length: 16133, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create accuracy table \n",
        "#importing confusion matrix\n",
        "confusion = confusion_matrix(y_test_lab_high, y_pred_high)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_lab_high, y_pred_high)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_lab_high, y_pred_high, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_lab_high, y_pred_high, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_lab_high, y_pred_high, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_lab_high, y_pred_high, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_lab_high, y_pred_high, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_lab_high, y_pred_high, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_lab_high, y_pred_high, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_lab_high, y_pred_high, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_lab_high, y_pred_high, average='weighted')))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_test_lab_high, y_pred_high, target_names=['No diabetes', 'Prediabetes', 'Diabetes']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPe8v1NutTJ",
        "outputId": "1d8f3eaf-3d57-4b1e-9f63-8df5d4f0a3bd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[12854   369     0]\n",
            " [  295    29     0]\n",
            " [ 2071   515     0]]\n",
            "\n",
            "Accuracy: 0.80\n",
            "\n",
            "Micro Precision: 0.80\n",
            "Micro Recall: 0.80\n",
            "Micro F1-score: 0.80\n",
            "\n",
            "Macro Precision: 0.29\n",
            "Macro Recall: 0.35\n",
            "Macro F1-score: 0.32\n",
            "\n",
            "Weighted Precision: 0.69\n",
            "Weighted Recall: 0.80\n",
            "Weighted F1-score: 0.74\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " No diabetes       0.84      0.97      0.90     13223\n",
            " Prediabetes       0.03      0.09      0.05       324\n",
            "    Diabetes       0.00      0.00      0.00      2586\n",
            "\n",
            "    accuracy                           0.80     16133\n",
            "   macro avg       0.29      0.35      0.32     16133\n",
            "weighted avg       0.69      0.80      0.74     16133\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat above for low \n",
        "# high index accuracies \n",
        "y_proba_low = new_model.predict(X_test_low)\n",
        "\n",
        "y_pred_low = y_proba_low.argmax(axis = 1) # want 0,1,2 vector\n",
        "\n",
        "# need to y_test to be single vector of 0,1,2 again\n",
        "y_test_lab_low = diabetes.iloc[y_test_low.index, :]['Diabetes_012']\n",
        "y_test_lab_low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj-eVpBSu-Ye",
        "outputId": "0998bc66-5add-49f2-ffe1-7b4331689e17"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "193256    0.0\n",
              "52416     0.0\n",
              "125094    0.0\n",
              "74892     0.0\n",
              "1357      0.0\n",
              "         ... \n",
              "87225     0.0\n",
              "70127     0.0\n",
              "78535     0.0\n",
              "210913    2.0\n",
              "72847     0.0\n",
              "Name: Diabetes_012, Length: 34603, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create accuracy table \n",
        "#importing confusion matrix\n",
        "confusion = confusion_matrix(y_test_lab_low, y_pred_low)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_lab_low, y_pred_low)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_lab_low, y_pred_low, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_lab_low, y_pred_low, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_lab_low, y_pred_low, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_lab_low, y_pred_low, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_lab_low, y_pred_low, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_lab_low, y_pred_low, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_lab_low, y_pred_low, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_lab_low, y_pred_low, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_lab_low, y_pred_low, average='weighted')))\n",
        "\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_test_lab_low, y_pred_low, target_names=['No diabetes', 'Prediabetes', 'Diabetes']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuhMhS7uvSAH",
        "outputId": "4068d331-18cc-454b-ebdb-326b1a89af3e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[28864   620     0]\n",
            " [  558    50     0]\n",
            " [ 3688   823     0]]\n",
            "\n",
            "Accuracy: 0.84\n",
            "\n",
            "Micro Precision: 0.84\n",
            "Micro Recall: 0.84\n",
            "Micro F1-score: 0.84\n",
            "\n",
            "Macro Precision: 0.30\n",
            "Macro Recall: 0.35\n",
            "Macro F1-score: 0.32\n",
            "\n",
            "Weighted Precision: 0.74\n",
            "Weighted Recall: 0.84\n",
            "Weighted F1-score: 0.79\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " No diabetes       0.87      0.98      0.92     29484\n",
            " Prediabetes       0.03      0.08      0.05       608\n",
            "    Diabetes       0.00      0.00      0.00      4511\n",
            "\n",
            "    accuracy                           0.84     34603\n",
            "   macro avg       0.30      0.35      0.32     34603\n",
            "weighted avg       0.74      0.84      0.79     34603\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uLfqIuciH4K2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}