---
title: '263 Project: Redo with Two Classes'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(MASS)
library(gbm)
library(glmnet)
library(nnet)
library(cvms)
library(tibble)
library(table1)
```



```{r}

#Loading the dataset 

diabetes <- read.csv(file = "diabetes_012_health_indicators_BRFSS2015.csv", header = TRUE)
#View(diabetes)

# move anyone from class 0 into class 1
diabetes$Diabetes_012[diabetes$Diabetes_012 == 0] <- 1
colnames(diabetes)[1] <- "Diabetes_12"

diabetes$Diabetes_12 <- as.factor(diabetes$Diabetes_12)

# factor_variables <- c(1:4,6:15,18:22) #the columns that should be factors
# 
# #making the variables as factors
# for (i in factor_variables){
#   diabetes[,i] <- as.factor(diabetes[,i])
# }

```


Table 1:

```{r}

diabetes_table1 <- diabetes

diabetes_table1$Diabetes_12 <- factor(diabetes_table1$Diabetes_12, levels = c("1", "2"), labels = c("Non-Diabetic or Prediabetic", "Diabetic"))
label(diabetes_table1$Diabetes_12) <- "Diabetes Status"

diabetes_table1$HighBP <- factor(diabetes_table1$HighBP, levels = c("0","1"), labels = c("No High BP", "High BP"))
label(diabetes_table1$HighBP) <- "Blood Pressure"

diabetes_table1$HighChol <- factor(diabetes_table1$HighChol, levels = c("0", "1"), labels = c("No High Cholesterol", "High Cholesterol"))
label(diabetes_table1$HighChol) <- "Cholesterol Level"

diabetes_table1$CholCheck <- factor(diabetes_table1$CholCheck, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$CholCheck) <- "Cholesterol Check in past 5 Years"

diabetes_table1$Smoker <- factor(diabetes_table1$Smoker, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$Smoker) <- "Smoked At Least 100 Cigs in Lifetime"

diabetes_table1$Stroke <- factor(diabetes_table1$Stroke, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$Stroke) <- "Ever Told Had a Stroke"

diabetes_table1$HeartDiseaseorAttack <- factor(diabetes_table1$HeartDiseaseorAttack , levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$HeartDiseaseorAttack) <- "CHD or Myocardial Infarction"

diabetes_table1$PhysActivity <- factor(diabetes_table1$PhysActivity , levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$PhysActivity) <- "Physical Activity in Past 30 Days"

diabetes_table1$Fruits <- factor(diabetes_table1$Fruits, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$Fruits) <- "Consume At Least 1 Fruit per Day"

diabetes_table1$Veggies <- factor(diabetes_table1$Veggies, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$Veggies) <- "Consume At Least 1 Vegetable per Day"

diabetes_table1$HvyAlcoholConsump <- factor(diabetes_table1$HvyAlcoholConsump, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$HvyAlcoholConsump) <- "Heavy Drinker"

diabetes_table1$AnyHealthcare <- factor(diabetes_table1$AnyHealthcare, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$AnyHealthcare) <- "Have Any Kind of Health Care Coverage"

diabetes_table1$NoDocbcCost <- factor(diabetes_table1$NoDocbcCost, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$NoDocbcCost) <- "Could Not See a Doctor in Past 12 Months Due To Cost"

diabetes_table1$GenHlth <- factor(diabetes_table1$GenHlth, levels = c("1", "2", "3", "4", "5"), labels = c("Excellent", "Very Good", "Good", "Fair", "Poor"))
label(diabetes_table1$GenHlth) <- "General Health Status"

label(diabetes_table1$MentHlth) <- "Nb Days Mental Health Not Good in Past 30 Days"

label(diabetes_table1$PhysHlth) <- "Nb Days Physical Health Not Good in Past 30 Days"

diabetes_table1$DiffWalk <- factor(diabetes_table1$DiffWalk, levels = c("0", "1"), labels = c("No", "Yes"))
label(diabetes_table1$DiffWalk) <- "Serious Difficulty Walking or Climbing Stairs"

diabetes_table1$Sex <- factor(diabetes_table1$Sex, levels = c("0", "1"), labels = c("Female", "Male"))
label(diabetes_table1$Sex) <- "Sex Assigned at Birth"

diabetes_table1$AgeBinary <- ifelse(diabetes_table1$Age < 9, "Young", "Old")
diabetes_table1$AgeBinary <- factor(diabetes_table1$AgeBinary, levels = c("Young", "Old"), labels = c("Less Than 60 Years Old", "At Least 60 Years Old"))
label(diabetes_table1$AgeBinary) <- "Age"

diabetes_table1$Education <- factor(diabetes_table1$Education, levels = c("1","2", "3", "4", "5", "6"), labels = c("Never Attended School", "Grades 1 Through 8 (Elementary)", "Grades 9 Through 11 (Some High School)", "Grade 12 or GED (High School Graduate)", "1 to 3 Years of College (Some College or Technical School)", " 4 or More Years of College (College Graduate)"))
label(diabetes_table1$Education) <- "Highest Education Level"

diabetes_table1$IncomeBinary <- ifelse(diabetes_table1$Income < 6, "Low", "High")
diabetes_table1$IncomeBinary <- factor(diabetes_table1$IncomeBinary, levels = c("Low", "High"), labels = c("At Most $35,000", "More Than $35,000"))
label(diabetes_table1$IncomeBinary) <- "Annual Income"


table1(~ Sex + AgeBinary + HighBP + HighChol + CholCheck + BMI + Smoker + Stroke + HeartDiseaseorAttack + PhysActivity + Fruits + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + MentHlth + PhysHlth + DiffWalk  + Education +  IncomeBinary | Diabetes_12, data = diabetes_table1, overall = "Total")


```

```{r}

set.seed(356) #Daniel's record

#splitting the dataset into train and test sets
n <- nrow(diabetes)
train_indices <- sample(1:n, size = 0.75*n, replace = F) #picking 3/4 of the dataset to be the training set and 25% to be the test set

train_set <- diabetes[train_indices, ] #training set
ytrain <- train_set$Diabetes_12

test_set <- diabetes[-train_indices, ] #test set
ytest <- test_set$Diabetes_12
```


<br>

<br>
```{r}
get_recall <- function(pred, target){
   TP = sum((pred==2) & (target==2))
   TN = sum((pred==1) & (target==1))
   FP = sum((pred==2) & (target==1))
   FN = sum((pred==1) & (target==2))
   recall = TP/(TP+FN)
   precision = TP/(TP+FP)
   accuracy = (TP+TN)/(TP+TN+FP+FN)
   recall
}

get_precision <- function(pred, target){
   TP = sum((pred==2) & (target==2))
   TN = sum((pred==1) & (target==1))
   FP = sum((pred==2) & (target==1))
   FN = sum((pred==1) & (target==2))
   accuracy = (TP+TN)/(TP+TN+FP+FN)
   accuracy
}

get_accuracy <- function(pred, target){
   TP = sum((pred==2) & (target==2))
   TN = sum((pred==1) & (target==1))
   FP = sum((pred==2) & (target==1))
   FN = sum((pred==1) & (target==2))
   accuracy = (TP+TN)/(TP+TN+FP+FN)
   accuracy
}
```


```{r}
evaluate_on_income <- function(pred, target, income) {
   df <- data.frame(pred, target, income)
   colnames(df) <- c('pred','target','income')
   list_metrices <- list()
   for (i in (1:8)){
      filtered_df = df[df$income==i, ]
      p = get_precision(filtered_df$pred, filtered_df$target)
      r = get_recall(filtered_df$pred, filtered_df$target)
      a = get_accuracy(filtered_df$pred, filtered_df$target)
      fraction = dim(filtered_df)[1]/dim(df)[1]
      list_metrices[[i]] = c(p, r, a, fraction)
   }
   list_metrices
}
```


```{r}
evaluate_on_education<- function(pred, target, education) {
   df <- data.frame(pred, target, education)
   colnames(df) <- c('pred','target','education')
   list_metrices <- list()
   for (i in (1:6)){
      filtered_df = df[df$education==i, ]
      print(dim(filtered_df)[1])
      p = get_precision(filtered_df$pred, filtered_df$target)
      r = get_recall(filtered_df$pred, filtered_df$target)
      a = get_accuracy(filtered_df$pred, filtered_df$target)
      fraction = dim(filtered_df)[1]/dim(df)[1]
      list_metrices[[i]] = c(p, r, a, fraction)
   }
   list_metrices
}
```

```{r}
evaluate_on_age<- function(pred, target, age) {
   df <- data.frame(pred, target, age)
   colnames(df) <- c('pred','target','age')
   list_metrices <- list()
   for (i in (1:13)){
      filtered_df = df[df$age==i, ]
      print(dim(filtered_df)[1])
      p = get_precision(filtered_df$pred, filtered_df$target)
      r = get_recall(filtered_df$pred, filtered_df$target)
      a = get_accuracy(filtered_df$pred, filtered_df$target)
      fraction = dim(filtered_df)[1]/dim(df)[1]
      list_metrices[[i]] = c(p, r, a, fraction)
   }
   list_metrices
}
```

```{r}
evaluate_on_binary_variables <- function(pred, target, variable_values, variable_name) {
   df <- data.frame(pred, target, variable_values)
   colnames(df) <- c('pred','target',variable_name)
   list_metrices <- list()
   for (i in (0:1)){
      filtered_df = df[df[,variable_name]==i, ]
      p = get_precision(filtered_df$pred, filtered_df$target)
      r = get_recall(filtered_df$pred, filtered_df$target)
      a = get_accuracy(filtered_df$pred, filtered_df$target)
      fraction = dim(filtered_df)[1]/dim(df)[1]
      list_metrices[[i+1]] = c(p, r, a, fraction)
   }
   list_metrices
}
```

1. LDA 

```{r}
#fitting LDA model using all the variables as predictors

lda_fit <- lda(Diabetes_12 ~ ., data = train_set, method = "mle")

#predictions using training set
fhat_train_lda <- predict(lda_fit, newdata = train_set, method = "plug-in")$class
train_error_lda <- mean(fhat_train_lda != ytrain) #training error
train_error_lda 

#predictions using test set
fhat_test_lda <- predict(lda_fit, newdata = test_set, method = "plug-in")$class
test_error_lda <- mean(fhat_test_lda != ytest) #test error
test_error_lda 
```


```{r}
# In the middle of each tile, we have the normalized count (overall percentage) and, beneath it, the count.
# At the bottom, we have the column percentage.
# At the right side of each tile, we have the row percentage. 


# LDA training 2x2 confusion matrix -- actual value, predicted value

train.matrix.lda <- as_tibble(table(ytrain, fhat_train_lda))

plot_confusion_matrix(train.matrix.lda, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_lda",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# LDA Test 2x2 confusion matrix -- actual value, predicted value

test.matrix.lda <- as_tibble(table(ytest, fhat_test_lda))

plot_confusion_matrix(test.matrix.lda, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_lda",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```


```{r}
#fitting LDA using only some variables 

lda_fit2 <- lda(Diabetes_12 ~ HighBP + HighChol + BMI + Smoker + PhysActivity + Veggies + HvyAlcoholConsump + PhysHlth + DiffWalk + Sex + Age + Income, data = train_set, method = "mle")

#predictions using training set
fhat_train_lda2 <- predict(lda_fit2, newdata = train_set, method = "plug-in")$class
train_error_lda2 <- mean(fhat_train_lda2 != ytrain)
train_error_lda2

#predictions using test set
fhat_test_lda2 <- predict(lda_fit2, newdata = test_set, method = "plug-in")$class
test_error_lda2 <- mean(fhat_test_lda2 != ytest)
test_error_lda2
```


```{r}
# LDA2 train 2x2 confusion matrix

train.matrix.lda2 <- as_tibble(table(ytrain, fhat_train_lda2))

plot_confusion_matrix(train.matrix.lda2, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_lda2",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# LDA2 test 2x2 confusion matrix

test.matrix.lda2 <- as_tibble(table(ytest, fhat_test_lda2))

plot_confusion_matrix(test.matrix.lda2, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_lda2",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```



<br>

<br>


2. QDA

```{r}
#fitting QDA model using all the variables as predictors

qda_fit <- qda(Diabetes_12 ~ ., data = train_set, method = "mle")

#predictions using training set
fhat_train_qda <- predict(qda_fit, newdata = train_set, method = "plug-in")$class
train_error_qda <- mean(fhat_train_qda != ytrain)
train_error_qda 

#predictions using test set
fhat_test_qda <- predict(qda_fit, newdata = test_set, method = "plug-in")$class
test_error_qda <- mean(fhat_test_qda != ytest)
test_error_qda 
```

```{r}
# QDA train 2x2 confusion matrix

train.matrix.qda <- as_tibble(table(ytrain, fhat_train_qda))

plot_confusion_matrix(train.matrix.qda, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_qda",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# QDA test 2x2 confusion matrix

test.matrix.qda <- as_tibble(table(ytest, fhat_test_qda))

plot_confusion_matrix(test.matrix.qda, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_qda",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```

interesting that QDA is correctly predicting more people who actually have diabetes (and is also falsely predicting too many people to have diabetes). this might actually be more useful

```{r}

#fitting QDA using only some variables 

qda_fit2 <- qda(Diabetes_12 ~ HighBP + HighChol + BMI + Smoker + PhysActivity + Veggies + HvyAlcoholConsump + PhysHlth + DiffWalk + Sex + Age + Income, data = train_set, method = "mle")

#predictions using training set
fhat_train_qda2 <- predict(qda_fit2, newdata = train_set, method = "plug-in")$class
train_error_qda2 <- mean(fhat_train_qda2 != ytrain)
train_error_qda2 

#predictions using test set
fhat_test_qda2 <- predict(qda_fit2, newdata = test_set, method = "plug-in")$class
test_error_qda2 <- mean(fhat_test_qda2 != ytest)
test_error_qda2 
```


```{r}
# QDA2 train 2x2 confusion matrix -- actual value, predicted value

train.matrix.qda2 <- as_tibble(table(ytrain, fhat_train_qda2))

plot_confusion_matrix(train.matrix.qda2, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_qda2",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# QDA2 test 2x2 confusion matrix -- actual value, predicted value

test.matrix.qda2 <- as_tibble(table(ytest, fhat_test_qda2))

plot_confusion_matrix(test.matrix.qda2, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_qda2",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```

<br>

<br>

3. Boosting

This takes 40 mins to run. 

```{r}
#creating a vector of lambdas for the boosting model
powers <- seq(-10, 0, by = 0.2)
lambdas <- 10^powers

train_error_boost <- vector()
test_error_boost <- vector()

#Fitting a boosting model for each lambda with 500 trees. I am using all the variables as predictors. I tried 1000 trees but it was taking so much time.

for (i in 1:length(lambdas)){

  #fitting boosting model
   boost_fit <- gbm(Diabetes_12 ~ ., data = train_set, distribution = "multinomial", n.trees = 500, shrinkage = lambdas[i])

   #training error
   phat_train_boost <- predict(boost_fit, train_set, n.trees = 500, type = "response")#getting the probabilities of each class
   fhat_train_boost <- apply(phat_train_boost, 1, which.max) - 1 #picking the class with the highest probability
   train_error_boost[i] <- mean(fhat_train_boost != ytrain)

   #test error
   phat_test_boost <- predict(boost_fit, test_set, n.trees = 500, type = "response") #getting the probabilities of each class
   fhat_test_boost <- apply(phat_test_boost, 1, which.max) - 1 #picking the class with the highest probability
   test_error_boost[i] <- mean(fhat_test_boost != ytest)

 }

#creating a data frame that has the train and test errors for each lambda
Errors <- data.frame(Lambda = lambdas, trainError = train_error_boost, testError = test_error_boost)
```


```{r}

#Plotting Training MSE vs lambda
Errors %>% ggplot(aes(x = Lambda, y = trainError))+
  geom_point(color = "cyan4", lwd = 1)+
  labs(x = "Shrinkage Parameter", y = "Training Error", title = "Training MSE for Different Values of the Shrinkage Parameter")+
  theme_bw()

#Plotting Test MSE vs lambda
Errors %>% ggplot(aes(x = Lambda, y = testError))+
  geom_point(color = "cyan4", lwd = 1)+
  labs(x = "Shrinkage Parameter", y = "Test Error", title = "Test MSE for Different Values of the Shrinkage Parameter")+
  theme_bw()

```


```{r}

#finding which lambda leads to the lowest test error
mintestError <- Errors$testError[which.min(Errors$testError)]
mintestError
minlambda <- Errors$Lambda[which.min(Errors$testError)]
minlambda
```

```{r}
# Running boostin model with minlambda 
boost_fit_best <- gbm(Diabetes_12 ~ ., data = train_set, distribution = "multinomial", n.trees = 500, shrinkage = minlambda)

#training error
phat_train_boost <- predict(boost_fit_best, train_set, n.trees = 500, type = "response")#getting the probabilities of each class
fhat_train_boost <- apply(phat_train_boost, 1, which.max) - 1 #picking the class with the highest probability
train_error_boost <- mean(fhat_train_boost != ytrain)

#test error
phat_test_boost <- predict(boost_fit_best, test_set, n.trees = 500, type = "response") #getting the probabilities of each class
fhat_test_boost <- apply(phat_test_boost, 1, which.max) - 1 #picking the class with the highest probability
test_error_boost <- mean(fhat_test_boost != ytest)
```

```{r}
# Boost train 2x2 confusion matrix

train.matrix.boost <- as_tibble(table(ytrain, fhat_train_boost))

plot_confusion_matrix(train.matrix.boost, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_boost",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# Boost test 2x2 confusion matrix

test.matrix.boost <- as_tibble(table(ytest, fhat_test_boost))

plot_confusion_matrix(test.matrix.boost, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_boost",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```


<br>

<br>


4. Logistic

```{r}
#Fitting a multinomial model with all variables as predictors.
logit_fit <- glm(Diabetes_12 ~ . , family = binomial(), data = train_set)

#training error
phat_train_logit <- predict(logit_fit, train_set, type = "response")
fhat_train_logit <- ifelse(phat_train_logit > 0.5, 2, 1)
train_error_logit <- mean(fhat_train_logit != ytrain)
train_error_logit 

#test error
phat_test_logit <- predict(logit_fit, test_set)
fhat_test_logit <- ifelse(phat_test_logit > 0.5, 2, 1)
test_error_logit <- mean(fhat_test_logit != ytest)
test_error_logit

```

can use a different cutoff for logistic!

```{r}
# logistic train 2x2 confusion matrix

train.matrix.logit <- as_tibble(table(ytrain, fhat_train_logit))

plot_confusion_matrix(train.matrix.logit, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_logit",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# logistic test 2x2 confusion matrix

test.matrix.logit <- as_tibble(table(ytest, fhat_test_logit))

plot_confusion_matrix(test.matrix.logit, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_logit",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```



Don't run this it will take 1 hour (literally). I ran it and the backward selection only removed the fruits and veggies variables. So I ran another multinomial model excluding fruits and veggies.
```{r}
#multinomial using backward selection to pick the best variables

#start <- multinom(Diabetes_012 ~ ., data = train_set)
#backward_multinom <- step(start, direction = "backward")
```

```{r}

#Multinomial model excluding fruits and veggies variable
logit_fit2 <- glm(Diabetes_12 ~ HighBP + HighChol + CholCheck + BMI + Smoker + Stroke + HeartDiseaseorAttack + PhysActivity + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + MentHlth + PhysHlth + DiffWalk + Sex + Age + Education + Income, family = binomial(), data = train_set )

#training error
phat_train_logit2 <- predict(logit_fit2, train_set)
fhat_train_logit2 <- ifelse(phat_train_logit2 > 0.5, 2, 1)
train_error_logit2 <- mean(fhat_train_logit2 != ytrain)
train_error_logit2 

#test error
phat_test_logit2 <- predict(logit_fit2, test_set)
fhat_test_logit2 <- ifelse(phat_test_logit2 > 0.5, 2, 1)
test_error_logit2 <- mean(fhat_test_logit2 != ytest)
test_error_logit2
```


```{r}
# logistic2 train 2x2 confusion matrix

train.matrix.logit2 <- as_tibble(table(ytrain, fhat_train_logit2))

plot_confusion_matrix(train.matrix.logit2, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_logit2",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# logistic2 test 2x2 confusion matrix

test.matrix.logit2 <- as_tibble(table(ytest, fhat_test_logit2))

plot_confusion_matrix(test.matrix.logit2, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_logit2",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```


<br>

<br>

5. LASSO

```{r}
xtrain <- model.matrix(Diabetes_12 ~ . , data = train_set) #creating a matrix for the train set
xtest <- model.matrix(Diabetes_12 ~ . , data = test_set) #creating a matrix for the test set

#Takes a bit of time to run 
lasso_fit <- glmnet(xtrain, ytrain, alpha = 1, family = "multinomial")

#Takes a lot of time to run.
cv.out <- cv.glmnet(xtrain, ytrain, alpha = 1, family = "multinomial", nfolds = 5) #choosing the best lambda by cross validation. I chose K = 5 folds, because if i keep the default of K = 10, it takes FOREVER to run

bestlambda <- cv.out$lambda.min #outputting the best lambda
bestlambda # = 5.28e-05

#training error
fhat_train_lasso <- predict(lasso_fit, s = bestlambda, newx = xtrain, type = "class")
train_error_lasso <- mean(fhat_train_lasso != ytrain)
train_error_lasso

#test error
fhat_test_lasso <- predict(lasso_fit, s = bestlambda, newx = xtest, type = "class")
test_error_lasso <- mean(fhat_test_lasso != ytest)
test_error_lasso
```

```{r}
# Lasso train 2x3 confusion matrix

train.matrix.lasso <- as_tibble(table(ytrain, fhat_train_lasso))

plot_confusion_matrix(train.matrix.lasso, 
                      target_col = "ytrain", 
                      prediction_col = "fhat_train_lasso",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )


# Lasso test 3x3 confusion matrix

test.matrix.lasso <- as_tibble(table(ytest, fhat_test_lasso))

plot_confusion_matrix(test.matrix.lasso, 
                      target_col = "ytest", 
                      prediction_col = "fhat_test_lasso",
                      counts_col = "n",
                      palette = "Greens",
                      add_sums = TRUE,
                      sums_settings = sum_tile_settings(
                        palette = "Oranges",
                        label = "Total",
                        tc_tile_border_color = "black"
                        )
                      )
```

6. GAMS

7. Neural networks

8. PCA

```{r}
#making the columns numeric, because the prcomp function requires numerical entries. 
for (i in 1:ncol(train_set)){
  train_set[,i] <- as.numeric(as.character(train_set[,i]))
}

#running PCA on the training dataset
pc_diabetes <- prcomp(train_set %>% dplyr::select(-Diabetes_12), scale = T)

#finding how many components to retain such that 90% of the variability is maintained.
lambda <- pc_diabetes$sdev^2
M <- min(which(cumsum(lambda)/sum(lambda) > 0.9))
M 

#extracting the new data
pc_diabetes_x <- as.data.frame(pc_diabetes$x)

#retaining the first M components
pc_retain <- pc_diabetes_x[, 1:M]

#combining the retained dataset + labels
pc_combined <- cbind(train_set$Diabetes_12, pc_retain)
colnames(pc_combined)[1] <- "Diabetes_12"
```

fitting a QDA model after performing PCA
```{r}
qda_fit_pc <- qda(as.factor(Diabetes_12) ~ . , data = pc_combined, method = "mle")
fhat_train_qda_pc <- predict(qda_fit_pc, newdata = pc_combined, method = "plug-in")$class
train_error_pc <- mean(fhat_train_qda_pc != pc_combined$Diabetes_12)
train_error_pc 
```

fitting QDA using test set
```{r}
for (i in 1:ncol(test_set)){
  test_set[,i] <- as.numeric(as.character(test_set[,i]))
}

#applying transformation to test set
new_test <- as.matrix(subset(test_set, select = -Diabetes_12)) %*% as.matrix(pc_diabetes$rotation)
#retaining first M PCs
new_test <- new_test[,1:M] 

#The fhat tests are all equal to 2. idk what went wrong. 
fhat_test_qda_pc <- predict(qda_fit_pc, newdata = as.data.frame(new_test), method = "plug-in")$class
test_error_pc <- mean(fhat_test_qda_pc != test_set$Diabetes_12)
test_error_pc

```



